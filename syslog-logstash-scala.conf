##################################################
# Syslog to Logstash to SCALA
#
# v1.0 	10/1/14	Doug McClure
#
###############################################
# NOTES:
#
# 1. This example shows four different TCP input flows based upon the source syslog type you are interested in exploring.
# 2. Update the patterns_dir parameter to match your patterns directory location where you've place the SYSLOGSCALA grok pattern file.
# 3. Multlines are addressed in each flow
# 4. Ensure that you set your host and path as needed for aggregation and consolidation in your SCALA datasource. 
# 5. Set a "final" tag to indicate all processing is done and message is ready to ship to SCALA via output
# 6. If parsing & annotation will be done in the SCALA Syslog Insight Pack, simply let the message exit the scala output by using a "final" tag. The output will automatically send host, path and message field to SCALA API.
#
###############################################

input {

	#rsyslog using SCALA DSV Content Pack
	tcp {
		port => 10515
		type => "rsyslog-scala-DSV"
	} #end tcp
	
	#syslog-ng using SCALA DSV Content pack
	tcp {
		port => 10516
		type => "syslog-ng-scala-DSV"
	} #end tcp
	
	#rsyslog using default SCALA Syslog Insight Pack
	tcp {
		port => 10517
		type => "rsyslog-scala-InsightPack"
	} #end tcp

	#syslog-ng using default SCALA Syslog Insight Pack
	tcp {
		port => 10518
		type => "syslog-ng-scala-InsightPack"
	} #end tcp
		
} #end inputs

filter {

###################

if [type] == "rsyslog-scala-DSV" {
    
	multiline {
		pattern => "^%{TIMESTAMP_ISO8601}"
		negate => "true"
		what => "previous"
	} #end multi
	
	grok {
		match => { "message" => "%{RSYSLOGDSV}" }
		patterns_dir => ["/opt/logstash150b1/patterns"]
        add_tag => ["rsyslog-grokked"]
	} #end grok
	
	#force through date filter to drop microseconds and give us this timestamp yyyy-MM-dd'T'HH:mm:ss.SSSX
	date {
		match => ["SourceTimestamp","ISO8601"]
		target => "@timestamp"
    } #end date
	
	mutate {
		replace => [ "host", "Syslog-DSVPack", "path", "Syslog-DSVPack"]
        add_tag => ["rsyslog-final"]
    } #end mutate
	
} #end conditional

#With properly configured message format templates in rsyslog and syslog-ng, these will pass through syslog messages to the default SCALA Syslog Insight Pack.

if [type] == "rsyslog-scala-InsightPack" {

	multiline {
		pattern => "^%{TIMESTAMP_ISO8601}"
		negate => "true"
		what => "previous"
	} #end multi

	mutate {
        replace => [ "host", "Syslog-InsightPack", "path", "Syslog-InsightPack"]
        add_tag => ["rsyslog-default-final"]
    } #end mutate
	
} #end conditional

if [type] == "syslog-ng-scala-DSV" {
	
	multiline {
		pattern => "^%{TIMESTAMP_ISO8601}"
		negate => "true"
		what => "previous"
	} #end multi
	
	grok {
		match => { "message" => "%{SYSLOGNGDSV}" }
		patterns_dir => ["/opt/logstash150b1/patterns"]
        add_tag => ["syslog-ng-grokked"]
	} #end grok
	
	mutate {
        replace => [ "host", "Syslog-DSVPack", "path", "Syslog-DSVPack"]
        add_tag => ["syslog-ng-final"]
    } #end mutate
	
} #end conditional

if [type] == "syslog-ng-scala-InsightPack" {
	
	multiline {
		pattern => "^%{TIMESTAMP_ISO8601}"
		negate => "true"
		what => "previous"
	} #end multi
	
	mutate {
        replace => [ "host", "Syslog-InsightPack", "path", "Syslog-InsightPack"]
        add_tag => ["syslog-ng-default-final"]
    } #end mutate
	
} #end conditional

######################
	
} #end filters

output {

###############################################	
#
#for new logstash scala outuput 

#type => "syslog-ng-scala-DSV" and type => "rsyslog-scala-DSV" - scala output defined  below
#type => "syslog-ng-scala-InsightPack" and type => "rsyslog-scala-InsightPack" - passed to Syslog Insight Pack (hostname, path and message field sent)

if "syslog-ng-default-final" in [tags] or "syslog-ng-final" in [tags] or "rsyslog-default-final" in [tags] or "rsyslog-final" in [tags] {
	scala { 
		scala_url => "https://10.0.0.1:9987/Unity/DataCollector"
		scala_user => "unityadmin" 
		scala_password => "unityadmin" 
		batch_size => 500000
		idle_flush_time => 5 
		sequential_flush => true
		num_concurrent_writers => 5
		use_structured_api => true
		disk_cache_path => "/opt/logstash/cache/tmp_spool_dir_Syslog"
		
		#"Syslog-InsightPack@Syslog-InsightPack" => "" <-- sent to Syslog AQL based Insight Pack via this output (the scala output sends host, path and message by default)
		
		scala_fields => {
		   "Syslog-DSVPack@Syslog-DSVPack" => "@timestamp,syslogHostname,syslogRelayHostname,tag,programName,processID,facility,severity,syslogAppName,message"
		} #end scala_fields
		date_format_string => "yyyy-MM-dd'T'HH:mm:ssX"
	} #end scala output
} #end scala output conditional


################################
# for debugging
################################

stdout
	{
	codec => rubydebug
	}

if "_grokparsefailure" in [tags] {
	file {
		codec => rubydebug
		path => "/opt/logstash/debug.log"
	} # end file 
} #end conditional

} #end outputs
